{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Siasmese_Net",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 14872952,
          "datasetId": 9514767,
          "databundleVersionId": 15735264
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/i-ganza007/Match_Backend/blob/main/Siasmese_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ianganza_livestock_images_path = kagglehub.dataset_download('ianganza/livestock-images')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "n8pXCgmqUvrV"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BbHzbX0K61P",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "Build a Siamese Network using a MobileNetV2 backbone to identify breed similarity for Project MATCH by processing cow images from 14 breeds located in \"/content/drive/MyDrive/Data\". The task involves generating balanced image pairs (limit 100 per class) for training, validation, and testing, implementing a Contrastive Loss function, and training the model with aggressive data augmentation, CosineAnnealingWarmRestarts, and early stopping before evaluating performance on the test set."
      ],
      "metadata": {
        "id": "7c6c133d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "### Subtask:\n",
        "Establish access to the dataset stored in Google Drive and verify the target directory structure.\n"
      ],
      "metadata": {
        "id": "e747016e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will mount Google Drive to access the dataset, define the base path, and verify the directory structure by listing the breed folders and counting files in sample directories.\n",
        "\n"
      ],
      "metadata": {
        "id": "c9c6b805"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "\n",
        "# 2. Define path to dataset\n",
        "dataset_path =\"/kaggle/input/datasets/ianganza/livestock-images/Data\"\n",
        "\n",
        "\n",
        "# 3. List contents to verify breed folders\n",
        "if os.path.exists(dataset_path):\n",
        "    breeds = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
        "    print(f'Total breed folders found: {len(breeds)}')\n",
        "    print('Breed folders:', breeds)\n",
        "\n",
        "    # 4. Count images in a few sample folders\n",
        "    for sample_breed in breeds[:3]:\n",
        "        breed_dir = os.path.join(dataset_path, sample_breed)\n",
        "        image_count = len([img for img in os.listdir(breed_dir) if os.path.isfile(os.path.join(breed_dir, img))])\n",
        "        print(f'Folder \"{sample_breed}\" contains {image_count} images.')\n",
        "else:\n",
        "    print(f'Error: Directory {dataset_path} not found. Please check the path.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88d689df",
        "outputId": "021ea928-081e-4752-c7d9-e7d562539c87",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T22:11:15.864656Z",
          "iopub.execute_input": "2026-02-25T22:11:15.864845Z",
          "iopub.status.idle": "2026-02-25T22:11:16.240514Z",
          "shell.execute_reply.started": "2026-02-25T22:11:15.864825Z",
          "shell.execute_reply": "2026-02-25T22:11:16.239805Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total breed folders found: 14\nBreed folders: ['indigenous_ankole_cow', 'sahiwal_cow', 'merino_sheep', 'brown_swiss_cow', 'girolando_cow', 'landrace_pig', 'jersey_cow', 'dorper_sheep', 'indigenous_goat', 'large_white_pig', 'indigenous_pig', 'pietrain_pig', 'fresian_cow', 'duroc_pig']\nFolder \"indigenous_ankole_cow\" contains 59 images.\nFolder \"sahiwal_cow\" contains 43 images.\nFolder \"merino_sheep\" contains 50 images.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 1: Data Preparation Logic\n",
        "\n",
        "### Subtask:\n",
        "Generate balanced image pairs (50/50 ratio) for training, validation, and testing sets with a limit of 100 pairs per class.\n"
      ],
      "metadata": {
        "id": "77c85237"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will import the necessary libraries, organize image paths by breed, and define a function to generate balanced (50/50) image pairs with a limit of 100 pairs per class before splitting them into training, validation, and testing sets.\n",
        "\n"
      ],
      "metadata": {
        "id": "2b5abda8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Organize image paths by breed\n",
        "breed_images = {}\n",
        "for breed in breeds:\n",
        "    breed_dir = os.path.join(dataset_path, breed)\n",
        "    images = [os.path.join(breed_dir, img) for img in os.listdir(breed_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    breed_images[breed] = images\n",
        "\n",
        "def generate_balanced_pairs(breed_dict, pairs_per_class=100):\n",
        "    pairs, labels = [], []\n",
        "    all_breeds = list(breed_dict.keys())\n",
        "    for breed in all_breeds:\n",
        "        images = breed_dict[breed]\n",
        "        if len(images) < 2: continue\n",
        "        # Positives\n",
        "        for _ in range(pairs_per_class // 2):\n",
        "            img1, img2 = random.sample(images, 2)\n",
        "            pairs.append((img1, img2))\n",
        "            labels.append(1)\n",
        "        # Negatives\n",
        "        other_breeds = [b for b in all_breeds if b != breed]\n",
        "        for _ in range(pairs_per_class // 2):\n",
        "            img1 = random.choice(images)\n",
        "            other_breed = random.choice(other_breeds)\n",
        "            img2 = random.choice(breed_dict[other_breed])\n",
        "            pairs.append((img1, img2))\n",
        "            labels.append(0)\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "X, y = generate_balanced_pairs(breed_images, pairs_per_class=100)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(f'Total pairs generated: {len(X)}')\n",
        "print(f'Train set: {len(X_train)} pairs ({sum(y_train)} positive)')\n",
        "print(f'Val set: {len(X_val)} pairs ({sum(y_val)} positive)')\n",
        "print(f'Test set: {len(X_test)} pairs ({sum(y_test)} positive)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd1d9727",
        "outputId": "dde131e2-77a5-4c99-ca36-56cbb3da8fa0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T22:11:16.242263Z",
          "iopub.execute_input": "2026-02-25T22:11:16.24257Z",
          "iopub.status.idle": "2026-02-25T22:11:19.000026Z",
          "shell.execute_reply.started": "2026-02-25T22:11:16.242537Z",
          "shell.execute_reply": "2026-02-25T22:11:18.999262Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Total pairs generated: 1400\nTrain set: 1120 pairs (560 positive)\nVal set: 140 pairs (70 positive)\nTest set: 140 pairs (70 positive)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 2: Model and Dataset Classes\n",
        "\n",
        "### Subtask:\n",
        "Define the custom PyTorch Dataset, Siamese Network architecture, and Contrastive Loss function.\n"
      ],
      "metadata": {
        "id": "97aca47a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will define the custom PyTorch Dataset for loading image pairs, create the Siamese Network using MobileNetV2 as a backbone, and implement the Contrastive Loss function to measure breed similarity as per the instructions.\n",
        "\n"
      ],
      "metadata": {
        "id": "f8ffd98e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# ==========================================\n",
        "# 1. ATTENTION MODULE (SCSAM)\n",
        "# ==========================================\n",
        "class SpatialChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
        "        )\n",
        "        self.conv_spatial = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        # Channel Attention\n",
        "        avg_out = self.fc(self.avg_pool(x).view(b, c)).view(b, c, 1, 1)\n",
        "        max_out = self.fc(self.max_pool(x).view(b, c)).view(b, c, 1, 1)\n",
        "        x = x * self.sigmoid(avg_out + max_out)\n",
        "        # Spatial Attention\n",
        "        avg_mask = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_mask, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        spatial_att = self.sigmoid(self.conv_spatial(torch.cat([avg_mask, max_mask], dim=1)))\n",
        "        return x * spatial_att\n",
        "\n",
        "# ==========================================\n",
        "# 2. SIAMESE NETWORK ARCHITECTURE\n",
        "# ==========================================\n",
        "class AttentionSiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_dim=512):\n",
        "        super().__init__()\n",
        "        # Using ResNet50 as the robust backbone\n",
        "        base = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "        self.features = nn.Sequential(*list(base.children())[:-2])\n",
        "        self.attention = SpatialChannelAttention(2048)\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward_once(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.attention(x)\n",
        "        x = self.pool(x).view(x.size(0), -1)\n",
        "        # L2 Normalization is critical for Triplet Loss distances\n",
        "        return F.normalize(self.fc(x), p=2, dim=1)\n",
        "\n",
        "    def forward(self, a, p, n):\n",
        "        return self.forward_once(a), self.forward_once(p), self.forward_once(n)\n",
        "\n",
        "# ==========================================\n",
        "# 3. DATASET & TRANSFORMS\n",
        "# ==========================================\n",
        "class SiameseTripletDataset(Dataset):\n",
        "    def __init__(self, breed_dict, transform=None, epoch_len=2000):\n",
        "        self.breed_dict = breed_dict\n",
        "        self.breeds = [b for b in breed_dict.keys() if len(breed_dict[b]) >= 2]\n",
        "        self.transform = transform\n",
        "        self.epoch_len = epoch_len\n",
        "\n",
        "    def __len__(self): return self.epoch_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_breed = random.choice(self.breeds)\n",
        "        a_path, p_path = random.sample(self.breed_dict[anchor_breed], 2)\n",
        "\n",
        "        neg_breed = random.choice([b for b in self.breeds if b != anchor_breed])\n",
        "        n_path = random.choice(self.breed_dict[neg_breed])\n",
        "\n",
        "        imgs = [Image.open(p).convert(\"RGB\") for p in [a_path, p_path, n_path]]\n",
        "        if self.transform:\n",
        "            imgs = [self.transform(img) for img in imgs]\n",
        "        return imgs[0], imgs[1], imgs[2]\n",
        "\n",
        "# --- Config & Setup ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Use breed_images from your previous data loading step\n",
        "train_loader = DataLoader(\n",
        "    SiameseTripletDataset(breed_images, transform=train_transform),\n",
        "    batch_size=16, shuffle=True\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING WITH TRIPLET LOSS\n",
        "# ==========================================\n",
        "\n",
        "\n",
        "model = AttentionSiameseNetwork(embedding_dim=512).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "\n",
        "print(f\"Starting Triplet Training on {device}...\")\n",
        "\n",
        "best_loss = float('inf')\n",
        "for epoch in range(25):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for a, p, n in train_loader:\n",
        "        a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        feat_a, feat_p, feat_n = model(a, p, n)\n",
        "\n",
        "        loss = criterion(feat_a, feat_p, feat_n)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1:02d}/25 | Triplet Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'best_triplet_model.pth')\n",
        "\n",
        "print(\"Refactored Training Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59ba5766",
        "outputId": "0bfd8dbd-089d-4580-b878-fbd9af886bd2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T22:11:19.00124Z",
          "iopub.execute_input": "2026-02-25T22:11:19.001725Z",
          "iopub.status.idle": "2026-02-25T23:45:45.977405Z",
          "shell.execute_reply.started": "2026-02-25T22:11:19.001687Z",
          "shell.execute_reply": "2026-02-25T23:45:45.976735Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 97.8M/97.8M [00:00<00:00, 205MB/s] \n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Starting Triplet Training on cuda...\nEpoch 01/25 | Triplet Loss: 0.4929\nEpoch 02/25 | Triplet Loss: 0.3202\nEpoch 03/25 | Triplet Loss: 0.2788\nEpoch 04/25 | Triplet Loss: 0.2324\nEpoch 05/25 | Triplet Loss: 0.1961\nEpoch 06/25 | Triplet Loss: 0.2089\nEpoch 07/25 | Triplet Loss: 0.1705\nEpoch 08/25 | Triplet Loss: 0.1803\nEpoch 09/25 | Triplet Loss: 0.1608\nEpoch 10/25 | Triplet Loss: 0.1480\nEpoch 11/25 | Triplet Loss: 0.1337\nEpoch 12/25 | Triplet Loss: 0.1218\nEpoch 13/25 | Triplet Loss: 0.1104\nEpoch 14/25 | Triplet Loss: 0.0982\nEpoch 15/25 | Triplet Loss: 0.1085\nEpoch 16/25 | Triplet Loss: 0.1051\nEpoch 17/25 | Triplet Loss: 0.0902\nEpoch 18/25 | Triplet Loss: 0.0862\nEpoch 19/25 | Triplet Loss: 0.0930\nEpoch 20/25 | Triplet Loss: 0.0896\nEpoch 21/25 | Triplet Loss: 0.0994\nEpoch 22/25 | Triplet Loss: 0.0865\nEpoch 23/25 | Triplet Loss: 0.0712\nEpoch 24/25 | Triplet Loss: 0.0774\nEpoch 25/25 | Triplet Loss: 0.0697\nRefactored Training Complete.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming tta_distances and y_test are ready\n",
        "pos_distances = [d for d, l in zip(tta_distances, y_test) if l == 1]\n",
        "neg_distances = [d for d, l in zip(tta_distances, y_test) if l == 0]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(pos_distances, label=\"Same Animal (Positive)\", fill=True)\n",
        "sns.kdeplot(neg_distances, label=\"Different Animal (Negative)\", fill=True)\n",
        "plt.title(\"Distribution of Distances: Are they actually separated?\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:45:45.97842Z",
          "iopub.execute_input": "2026-02-25T23:45:45.978838Z",
          "iopub.status.idle": "2026-02-25T23:45:46.357135Z",
          "shell.execute_reply.started": "2026-02-25T23:45:45.978813Z",
          "shell.execute_reply": "2026-02-25T23:45:46.35587Z"
        },
        "id": "rhmv6uUeUvrx",
        "outputId": "b0591ee4-8560-4012-9807-6666bb107312"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_55/1355157291.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Assuming tta_distances and y_test are ready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpos_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtta_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mneg_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtta_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tta_distances' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'tta_distances' is not defined",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 3: Optimized Training Pipeline\n",
        "\n",
        "### Subtask:\n",
        "Configure the training loop using Adam with weight decay, CosineAnnealingWarmRestarts, and Gradient Clipping, including early stopping.\n"
      ],
      "metadata": {
        "id": "67a12f46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will initialize the model, datasets, and data loaders, then define the optimizer and scheduler before implementing the training loop with gradient clipping and early stopping as requested.\n",
        "\n"
      ],
      "metadata": {
        "id": "6e46e8a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "Evaluate the Siamese Network's performance on the test set for project MATCH. Load the best model weights from \"best_siamese_model.pth\", calculate Euclidean distances for all image pairs in the test set (\"X_test\", \"y_test\"), and compute final metrics including accuracy, precision, recall, and F1-score using a 0.5 distance threshold. Generate a confusion matrix and perform a visual error analysis by plotting correctly and incorrectly classified pairs with their predicted distances to summarize the model's effectiveness in breed similarity identification."
      ],
      "metadata": {
        "id": "04c196dd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Best Model Weights\n",
        "\n",
        "### Subtask:\n",
        "Initialize the Siamese Network and load the saved optimal weights for evaluation on the test set.\n"
      ],
      "metadata": {
        "id": "ada04a40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will verify the existence of the saved weights file, instantiate the Siamese Network, load the state dictionary, and move the model to the appropriate device in evaluation mode.\n",
        "\n"
      ],
      "metadata": {
        "id": "6accbc89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Set Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Process the test set pairs through the loaded Siamese Network to calculate Euclidean distances and collect true labels.\n"
      ],
      "metadata": {
        "id": "37fec371"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will initialize the test dataset and DataLoader, then perform inference with the Siamese Network to calculate Euclidean distances between image pairs and collect the ground truth labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "3d187c58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "The inference on the test set is complete, and the distances and labels are collected. Now I will calculate the performance metrics (accuracy, precision, recall, and F1-score) using a 0.8 threshold and display the confusion matrix.\n",
        "\n"
      ],
      "metadata": {
        "id": "114a4e97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task\n",
        "# Task\n",
        "Optimize and finalize the evaluation of the Siamese Network for breed similarity identification in Project MATCH. Implement Test-Time Augmentation (TTA) by averaging Euclidean distances across 10 stochastic forward passes with training transforms for each pair in the test set (`X_test`, `y_test`). Search for the optimal distance threshold within the range of 0.3 to 1.3 to maximize the F1-score. Finally, generate a comprehensive performance report including Accuracy, Precision, Recall, and F1-score using the optimized threshold and TTA distances, and visualize the results with a confusion matrix to conclude the model evaluation phase."
      ],
      "metadata": {
        "id": "3c872d41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement TTA Logic\n",
        "\n",
        "### Subtask:\n",
        "Define and integrate a function for Test-Time Augmentation (TTA) to compute robust Euclidean distances for image pairs.\n"
      ],
      "metadata": {
        "id": "3f6dfc19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will implement a Test-Time Augmentation (TTA) function that uses stochastic forward passes with training transforms and dropout to compute a robust average Euclidean distance between image pairs.\n",
        "\n"
      ],
      "metadata": {
        "id": "0eac6bdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "def get_tta_distance(path1, path2, model, device, num_aug=5):\n",
        "    model.eval()\n",
        "    # Clean paths to prevent loading errors\n",
        "    path1 = str(path1).strip(\"[]'\\\"\\n \")\n",
        "    path2 = str(path2).strip(\"[]'\\\"\\n \")\n",
        "\n",
        "    img1_pil = Image.open(path1).convert('RGB')\n",
        "    img2_pil = Image.open(path2).convert('RGB')\n",
        "\n",
        "    dists = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_aug):\n",
        "            # Apply training transforms for augmentation variety\n",
        "            t1 = train_transform(img1_pil).unsqueeze(0).to(device)\n",
        "            t2 = train_transform(img2_pil).unsqueeze(0).to(device)\n",
        "\n",
        "            # USE forward_once instead of forward() to avoid the 'n' argument error\n",
        "            feat1 = model.forward_once(t1)\n",
        "            feat2 = model.forward_once(t2)\n",
        "\n",
        "            dist = F.pairwise_distance(feat1, feat2)\n",
        "            dists.append(dist.item())\n",
        "\n",
        "    return np.mean(dists)\n",
        "\n",
        "# --- Execute TTA Calculation ---\n",
        "print(\"Calculating TTA Distances for Test Set...\")\n",
        "tta_distances = []\n",
        "for i, p in enumerate(X_test):\n",
        "    d = get_tta_distance(p[0], p[1], model, device, num_aug=5)\n",
        "    tta_distances.append(d)\n",
        "    if (i+1) % 50 == 0:\n",
        "        print(f\"Processed {i+1}/{len(X_test)} pairs...\")\n",
        "\n",
        "print(\"TTA Distances calculated successfully.\")"
      ],
      "metadata": {
        "id": "f6aed085",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:48:16.104636Z",
          "iopub.execute_input": "2026-02-25T23:48:16.105207Z",
          "iopub.status.idle": "2026-02-25T23:48:43.575638Z",
          "shell.execute_reply.started": "2026-02-25T23:48:16.105176Z",
          "shell.execute_reply": "2026-02-25T23:48:43.574884Z"
        },
        "outputId": "1e3dac15-392b-46ad-ae83-5d27ba7b3c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Calculating TTA Distances for Test Set...\nProcessed 50/140 pairs...\nProcessed 100/140 pairs...\nTTA Distances calculated successfully.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute TTA Optimized Distances\n",
        "\n",
        "### Subtask:\n",
        "Apply the TTA function to the entire test set (X_test) to generate a new set of refined distances.\n"
      ],
      "metadata": {
        "id": "8a06f9a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will iterate through the test set pairs and apply the `get_tta_distance` function with 10 augmentations per pair to compute refined distances.\n",
        "\n"
      ],
      "metadata": {
        "id": "fc6e7ac0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Convert to numpy for easier indexing\n",
        "tta_distances = np.array(tta_distances)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "pos_distances = tta_distances[y_test == 1]\n",
        "neg_distances = tta_distances[y_test == 0]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "if len(pos_distances) > 0:\n",
        "    sns.kdeplot(pos_distances, label=\"Same Animal (Positive)\", fill=True, color='green')\n",
        "if len(neg_distances) > 0:\n",
        "    sns.kdeplot(neg_distances, label=\"Different Animal (Negative)\", fill=True, color='red')\n",
        "\n",
        "plt.axvline(x=0.8, color='blue', linestyle='--', label='Initial Threshold Guess')\n",
        "plt.title(\"Biometric Separation: Triplet-Attention Model\")\n",
        "plt.xlabel(\"Euclidean Distance\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9a3ce36d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:49:09.657807Z",
          "iopub.execute_input": "2026-02-25T23:49:09.658614Z",
          "iopub.status.idle": "2026-02-25T23:49:09.964742Z",
          "shell.execute_reply.started": "2026-02-25T23:49:09.65858Z",
          "shell.execute_reply": "2026-02-25T23:49:09.964053Z"
        },
        "outputId": "0cc6bc11-1a17-45b9-cb95-1a2c4b004d48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x600 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "U7qkByRdUvr6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Threshold Optimization\n",
        "\n",
        "### Subtask:\n",
        "Iterate through a range of distance thresholds (0.3 to 1.3) to find the specific value that maximizes the F1-score for breed similarity detection.\n"
      ],
      "metadata": {
        "id": "0dda7801"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will iterate through threshold values from 0.3 to 1.3 to find the one that maximizes the F1-score based on the TTA distances and ground truth labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "187c5316"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Performance Report\n",
        "\n",
        "### Subtask:\n",
        "Generate a comprehensive evaluation report and confusion matrix using the optimized threshold and TTA distances.\n"
      ],
      "metadata": {
        "id": "39aefee0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning**:\n",
        "I will calculate the final evaluation metrics and visualize the results using the optimized threshold and TTA distances to summarize the model's performance on the test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "ef7eaa3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "best_f1 = 0\n",
        "optimal_t = 0\n",
        "\n",
        "# Scan potential thresholds to find the best F1\n",
        "for t in np.linspace(min(tta_distances), max(tta_distances), 100):\n",
        "    preds = (tta_distances < t).astype(int)\n",
        "    current_f1 = f1_score(y_test, preds)\n",
        "    if current_f1 > best_f1:\n",
        "        best_f1 = current_f1\n",
        "        optimal_t = t\n",
        "\n",
        "# Calculate final metrics at the best threshold\n",
        "final_preds = (tta_distances < optimal_t).astype(int)\n",
        "\n",
        "print(f\"--- FINAL PERFORMANCE REPORT ---\")\n",
        "print(f\"Optimal Threshold: {optimal_t:.4f}\")\n",
        "print(f\"Accuracy:          {accuracy_score(y_test, final_preds):.4f}\")\n",
        "print(f\"Precision:         {precision_score(y_test, final_preds):.4f}\")\n",
        "print(f\"Recall:            {recall_score(y_test, final_preds):.4f}\")\n",
        "print(f\"F1-Score:          {f1_score(y_test, final_preds):.4f}\")"
      ],
      "metadata": {
        "id": "9713bfed",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:49:19.45467Z",
          "iopub.execute_input": "2026-02-25T23:49:19.454974Z",
          "iopub.status.idle": "2026-02-25T23:49:19.628056Z",
          "shell.execute_reply.started": "2026-02-25T23:49:19.454948Z",
          "shell.execute_reply": "2026-02-25T23:49:19.627466Z"
        },
        "outputId": "da49a9e4-1efb-4491-ba5d-dc6c9eb7d7b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--- FINAL PERFORMANCE REPORT ---\nOptimal Threshold: 0.5787\nAccuracy:          0.9571\nPrecision:         0.9211\nRecall:            1.0000\nF1-Score:          0.9589\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_livestock(img1_path, img2_path, threshold=0.4420):\n",
        "    model.eval()\n",
        "\n",
        "    # Load and transform\n",
        "    img1 = val_test_transform(Image.open(img1_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "    img2 = val_test_transform(Image.open(img2_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        feat1 = model.forward_once(img1)\n",
        "        feat2 = model.forward_once(img2)\n",
        "\n",
        "        # Calculate Euclidean distance\n",
        "        distance = torch.norm(feat1 - feat2, dim=1).item()\n",
        "\n",
        "    is_match = distance < threshold\n",
        "    confidence = max(0, 100 - (distance / threshold * 50)) if is_match else min(100, (distance / threshold * 50))\n",
        "\n",
        "    print(f\"Distance: {distance:.4f}\")\n",
        "    print(f\"Match Detected: {is_match}\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")\n",
        "    return is_match, distance\n",
        "\n",
        "# Example Usage:\n",
        "verify_livestock(\"path_to_cow_a.jpg\", \"path_to_cow_b.jpg\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:45:46.361477Z",
          "iopub.status.idle": "2026-02-25T23:45:46.362197Z",
          "shell.execute_reply.started": "2026-02-25T23:45:46.362013Z",
          "shell.execute_reply": "2026-02-25T23:45:46.362039Z"
        },
        "id": "InX74GykUvr_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 1. Load model architecture and weights\n",
        "model = AttentionSiameseNetwork(embedding_dim=512)\n",
        "model.load_state_dict(torch.load('best_triplet_model.pth', map_location='cpu'))\n",
        "model.eval()\n",
        "\n",
        "# 2. Create a wrapper or use forward_once directly for the export\n",
        "# We only want the model to take ONE image and give ONE embedding in TFLite\n",
        "class ExportWrapper(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "    def forward(self, x):\n",
        "        return self.model.forward_once(x)\n",
        "\n",
        "export_model = ExportWrapper(model)\n",
        "export_model.eval()\n",
        "\n",
        "# 3. Create dummy input (1 image, 3 channels, 224x224)\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# 4. Export to ONNX\n",
        "torch.onnx.export(\n",
        "    export_model,\n",
        "    dummy_input,\n",
        "    \"livestock_biometric.onnx\",\n",
        "    export_params=True,\n",
        "    opset_version=12,\n",
        "    do_constant_folding=True,\n",
        "    input_names=['input_image'],\n",
        "    output_names=['biometric_embedding'],\n",
        "    dynamic_axes={'input_image': {0: 'batch_size'}, 'biometric_embedding': {0: 'batch_size'}}\n",
        ")\n",
        "\n",
        "print(\"✅ ONNX Export Successful! You can now proceed to TFLite conversion.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:49:33.190028Z",
          "iopub.execute_input": "2026-02-25T23:49:33.19031Z",
          "iopub.status.idle": "2026-02-25T23:49:35.510604Z",
          "shell.execute_reply.started": "2026-02-25T23:49:33.190288Z",
          "shell.execute_reply": "2026-02-25T23:49:35.509901Z"
        },
        "id": "JdOOPJBgUvsA",
        "outputId": "ff160eb7-3965-413d-fd7f-9c96bdaa896d"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_55/3134761055.py:24: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n  torch.onnx.export(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "✅ ONNX Export Successful! You can now proceed to TFLite conversion.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Use onnx2tf to go straight from ONNX to TFLite\n",
        "# -i: input onnx file\n",
        "# -o: output folder\n",
        "# -ois: output integer quantization (optional, but makes it fast)\n",
        "!onnx2tf -i livestock_biometric.onnx -o tf_saved_model\n",
        "# The file will be inside the livestock_tflite_out folder\n",
        "print(\"Check the 'livestock_tflite_out' folder for your .tflite file!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:57:05.957997Z",
          "iopub.execute_input": "2026-02-25T23:57:05.958799Z",
          "iopub.status.idle": "2026-02-26T00:02:04.551181Z",
          "shell.execute_reply.started": "2026-02-25T23:57:05.958766Z",
          "shell.execute_reply": "2026-02-26T00:02:04.550397Z"
        },
        "id": "_gnBpo0AUvsB",
        "outputId": "5f1fa4f9-c451-4433-f498-d2034fc7938c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n\u001b[07mModel optimizing started\u001b[0m ============================================================\nSimplifying...\nFinish! Here is the difference:\n┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n┃                    ┃ Original Model ┃ Simplified Model ┃\n┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n│ Add                │ 17             │ 17               │\n│ BatchNormalization │ 1              │ 1                │\n│ Clip               │ 1              │ 1                │\n│ Concat             │ 6              │ 2                │\n│ Constant           │ 126            │ 122              │\n│ Conv               │ 54             │ 54               │\n│ Div                │ 1              │ 1                │\n│ Expand             │ 1              │ 1                │\n│ Gather             │ 3              │ 1                │\n│ Gemm               │ 2              │ 2                │\n│ GlobalAveragePool  │ 2              │ 2                │\n│ Identity           │ 2              │ 0                │\n│ MatMul             │ 4              │ 4                │\n│ MaxPool            │ 2              │ 2                │\n│ Mul                │ 2              │ 2                │\n│ ReduceL2           │ 1              │ 1                │\n│ ReduceMax          │ 1              │ 1                │\n│ ReduceMean         │ 1              │ 1                │\n│ Relu               │ 52             │ 52               │\n│ Reshape            │ 5              │ 5                │\n│ Shape              │ 4              │ 2                │\n│ Sigmoid            │ 2              │ 2                │\n│ Unsqueeze          │ 9              │ 1                │\n│ Model Size         │ 101.6MiB       │ 101.6MiB         │\n└────────────────────┴────────────────┴──────────────────┘\n\nSimplifying...\nFinish! Here is the difference:\n┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n┃                    ┃ Original Model ┃ Simplified Model ┃\n┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n│ Add                │ 17             │ 17               │\n│ BatchNormalization │ 1              │ 1                │\n│ Clip               │ 1              │ 1                │\n│ Concat             │ 2              │ 2                │\n│ Constant           │ 122            │ 122              │\n│ Conv               │ 54             │ 54               │\n│ Div                │ 1              │ 1                │\n│ Expand             │ 1              │ 1                │\n│ Gather             │ 1              │ 1                │\n│ Gemm               │ 2              │ 2                │\n│ GlobalAveragePool  │ 2              │ 2                │\n│ MatMul             │ 4              │ 4                │\n│ MaxPool            │ 2              │ 2                │\n│ Mul                │ 2              │ 2                │\n│ ReduceL2           │ 1              │ 1                │\n│ ReduceMax          │ 1              │ 1                │\n│ ReduceMean         │ 1              │ 1                │\n│ Relu               │ 52             │ 52               │\n│ Reshape            │ 5              │ 5                │\n│ Shape              │ 2              │ 2                │\n│ Sigmoid            │ 2              │ 2                │\n│ Unsqueeze          │ 1              │ 1                │\n│ Model Size         │ 101.6MiB       │ 101.6MiB         │\n└────────────────────┴────────────────┴──────────────────┘\n\nSimplifying...\nFinish! Here is the difference:\n┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n┃                    ┃ Original Model ┃ Simplified Model ┃\n┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n│ Add                │ 17             │ 17               │\n│ BatchNormalization │ 1              │ 1                │\n│ Clip               │ 1              │ 1                │\n│ Concat             │ 2              │ 2                │\n│ Constant           │ 122            │ 122              │\n│ Conv               │ 54             │ 54               │\n│ Div                │ 1              │ 1                │\n│ Expand             │ 1              │ 1                │\n│ Gather             │ 1              │ 1                │\n│ Gemm               │ 2              │ 2                │\n│ GlobalAveragePool  │ 2              │ 2                │\n│ MatMul             │ 4              │ 4                │\n│ MaxPool            │ 2              │ 2                │\n│ Mul                │ 2              │ 2                │\n│ ReduceL2           │ 1              │ 1                │\n│ ReduceMax          │ 1              │ 1                │\n│ ReduceMean         │ 1              │ 1                │\n│ Relu               │ 52             │ 52               │\n│ Reshape            │ 5              │ 5                │\n│ Shape              │ 2              │ 2                │\n│ Sigmoid            │ 2              │ 2                │\n│ Unsqueeze          │ 1              │ 1                │\n│ Model Size         │ 101.6MiB       │ 101.6MiB         │\n└────────────────────┴────────────────┴──────────────────┘\n\n\u001b[32mModel optimizing complete!\u001b[0m\n\n\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n\n\u001b[07mModel loaded\u001b[0m ========================================================================\n\n\u001b[07mModel conversion started\u001b[0m ============================================================\n\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input_image \u001b[32mshape\u001b[0m: ['batch_size', 3, 224, 224] \u001b[32mdtype\u001b[0m: float32\n\n\u001b[32mINFO:\u001b[0m \u001b[32m2 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.0/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input_image \u001b[36mshape\u001b[0m: ['batch_size', 3, 224, 224] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_573 \u001b[36mshape\u001b[0m: [64, 3, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_574 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 112, 112] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad/Pad:0 \u001b[34mshape\u001b[0m: (None, 230, 230, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (7, 7, 3, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (None, 112, 112, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m3 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 112, 112] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 112, 112] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (None, 112, 112, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (None, 112, 112, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m4 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /features/features.3/MaxPool\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 112, 112] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.3/MaxPool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[33mWARNING:\u001b[0m Tensorflow incompatible padding detected. Extra pad layer is inserted automatically. \n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (None, 112, 112, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [3, 3] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [[0, 0], [1, 1], [1, 1], [0, 0]] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n\n\u001b[32mINFO:\u001b[0m \u001b[32m5 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.3/MaxPool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_576 \u001b[36mshape\u001b[0m: [64, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_577 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m6 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/downsample/downsample.0/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.3/MaxPool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_585 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_586 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m7 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m8 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_579 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_580 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m9 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m10 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_582 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_583 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m11 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.4/features.4.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_1/transpose:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_2/transpose:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m12 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.0/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_7/Add:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m13 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_588 \u001b[36mshape\u001b[0m: [64, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_589 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_3/transpose:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m14 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_8/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m15 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_591 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_592 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m16 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_9/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m17 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_594 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_595 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_5/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_10/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m18 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.4/features.4.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_6/transpose:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_7/transpose:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m19 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.1/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_13/Add:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_6/Relu:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m20 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_597 \u001b[36mshape\u001b[0m: [64, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_598 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_8/transpose:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m21 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_14/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m22 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_600 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_601 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_7/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m23 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_15/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m24 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 64, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_603 \u001b[36mshape\u001b[0m: [256, 64, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_604 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_8/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 64, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_16/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m25 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.4/features.4.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_11/transpose:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_12/transpose:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m26 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.4/features.4.2/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/features.4.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_19/Add:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_9/Relu:0 \u001b[34mshape\u001b[0m: (None, 256, 56, 56) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m27 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_606 \u001b[36mshape\u001b[0m: [128, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_607 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_13/transpose:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m28 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/downsample/downsample.0/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/features.4.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_615 \u001b[36mshape\u001b[0m: [512, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_616 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_14/transpose:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_21/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m29 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_20/Add:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_10/Relu:0 \u001b[34mshape\u001b[0m: (None, 56, 56, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m30 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 56, 56] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_609 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_610 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_2/Pad:0 \u001b[34mshape\u001b[0m: (None, 58, 58, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m31 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_22/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m32 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_612 \u001b[36mshape\u001b[0m: [512, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_613 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_11/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_23/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m33 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.5/features.5.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_16/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_17/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m34 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.0/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_26/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_12/Relu:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m35 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_618 \u001b[36mshape\u001b[0m: [128, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_619 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_18/transpose:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m36 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_27/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m37 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_621 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_622 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_13/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m38 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_28/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m39 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_624 \u001b[36mshape\u001b[0m: [512, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_625 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_14/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_29/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m40 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.5/features.5.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_21/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_22/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m41 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.1/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_32/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_15/Relu:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m42 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_627 \u001b[36mshape\u001b[0m: [128, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_628 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_23/transpose:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m43 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_33/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m44 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_630 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_631 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_16/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m45 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_34/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m46 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_633 \u001b[36mshape\u001b[0m: [512, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_634 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_17/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_35/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m47 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.5/features.5.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_26/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_27/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m48 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.2/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_38/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_18/Relu:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m49 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_636 \u001b[36mshape\u001b[0m: [128, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_637 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_28/transpose:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m50 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_39/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m51 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_639 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_640 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_19/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m52 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_40/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m53 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 128, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_642 \u001b[36mshape\u001b[0m: [512, 128, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_643 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_20/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 128, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_41/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m54 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.5/features.5.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_31/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_32/transpose:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m55 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.5/features.5.3/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/features.5.3/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_44/Add:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_21/Relu:0 \u001b[34mshape\u001b[0m: (None, 512, 28, 28) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m56 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_645 \u001b[36mshape\u001b[0m: [256, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_646 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_33/transpose:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m57 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/downsample/downsample.0/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/features.5.3/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_654 \u001b[36mshape\u001b[0m: [1024, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_655 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_34/transpose:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_46/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m58 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_45/Add:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_22/Relu:0 \u001b[34mshape\u001b[0m: (None, 28, 28, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m59 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 28, 28] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_648 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_649 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_3/Pad:0 \u001b[34mshape\u001b[0m: (None, 30, 30, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m60 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_47/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m61 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_651 \u001b[36mshape\u001b[0m: [1024, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_652 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_23/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_48/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m62 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.6/features.6.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_36/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_37/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m63 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.0/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_51/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_24/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m64 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_657 \u001b[36mshape\u001b[0m: [256, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_658 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_38/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m65 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_52/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m66 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_660 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_661 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_25/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m67 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_53/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m68 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_663 \u001b[36mshape\u001b[0m: [1024, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_664 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_26/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_54/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m69 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.6/features.6.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_41/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_42/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m70 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.1/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_57/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_27/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m71 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_666 \u001b[36mshape\u001b[0m: [256, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_667 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_43/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m72 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_58/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m73 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_669 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_670 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_28/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m74 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_59/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_29/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m75 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_672 \u001b[36mshape\u001b[0m: [1024, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_673 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_29/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_60/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m76 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.6/features.6.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_46/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_47/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m77 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.2/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_63/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_30/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m78 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_675 \u001b[36mshape\u001b[0m: [256, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_676 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_48/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m79 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_64/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_31/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m80 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_678 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_679 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_31/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m81 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_65/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m82 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_681 \u001b[36mshape\u001b[0m: [1024, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_682 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_32/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_66/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m83 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.6/features.6.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_51/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_52/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m84 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.3/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.3/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_69/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_33/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m85 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.3/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_684 \u001b[36mshape\u001b[0m: [256, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_685 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_53/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m86 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_70/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_34/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m87 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_687 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_688 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_34/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m88 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_71/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_35/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m89 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_690 \u001b[36mshape\u001b[0m: [1024, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_691 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_35/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_72/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m90 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.6/features.6.3/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_56/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_57/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m91 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.4/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.4/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_75/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_36/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m92 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.4/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_693 \u001b[36mshape\u001b[0m: [256, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_694 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_58/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m93 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_76/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_37/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m94 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_696 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_697 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_37/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_77/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m95 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_77/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m96 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 256, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_699 \u001b[36mshape\u001b[0m: [1024, 256, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_700 \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_38/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 256, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_78/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m97 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.6/features.6.4/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_61/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_62/transpose:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m98 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/features.6.5/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/features.6.5/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_81/Add:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_39/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024, 14, 14) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m99 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_702 \u001b[36mshape\u001b[0m: [512, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_703 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_63/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m100 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/downsample/downsample.0/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/features.6.5/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 1024, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_711 \u001b[36mshape\u001b[0m: [2048, 1024, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_712 \u001b[36mshape\u001b[0m: [2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_64/transpose:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 1024, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (2048,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_83/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m101 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_82/Add:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_40/Relu:0 \u001b[34mshape\u001b[0m: (None, 14, 14, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m102 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 14, 14] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_705 \u001b[36mshape\u001b[0m: [512, 512, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_706 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.pad_4/Pad:0 \u001b[34mshape\u001b[0m: (None, 16, 16, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 512, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: VALID \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_84/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m103 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_84/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_41/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m104 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_708 \u001b[36mshape\u001b[0m: [2048, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_709 \u001b[36mshape\u001b[0m: [2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_41/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (2048,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_85/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m105 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.7/features.7.0/downsample/downsample.0/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_66/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_67/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_88/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m106 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.0/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_88/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_42/Relu:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m107 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_714 \u001b[36mshape\u001b[0m: [512, 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_715 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_68/transpose:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 2048, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_89/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m108 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_89/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_43/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m109 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_717 \u001b[36mshape\u001b[0m: [512, 512, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_718 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_43/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 512, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_90/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m110 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_90/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_44/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m111 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_720 \u001b[36mshape\u001b[0m: [2048, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_721 \u001b[36mshape\u001b[0m: [2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_44/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (2048,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_91/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m112 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.7/features.7.0/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_71/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_72/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_94/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m113 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.1/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_94/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_45/Relu:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m114 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/conv1/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_723 \u001b[36mshape\u001b[0m: [512, 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_724 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_73/transpose:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 2048, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m115 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/relu/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_95/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_46/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m116 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/conv2/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/relu/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_726 \u001b[36mshape\u001b[0m: [512, 512, 3, 3] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_727 \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_46/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 512, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_96/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m117 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/relu_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_96/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m118 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/conv3/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/relu_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 512, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_729 \u001b[36mshape\u001b[0m: [2048, 512, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_730 \u001b[36mshape\u001b[0m: [2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_47/Relu:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (1, 1, 512, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (2048,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_97/Add:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m119 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/conv3/Conv_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /features/features.7/features.7.1/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_76/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_77/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_100/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m120 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.7/features.7.2/relu_2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/Add_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/features.7.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_100/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_48/Relu:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m121 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: /attention/avg_pool/GlobalAveragePool\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/avg_pool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_78/transpose:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean/Mean:0 \u001b[34mshape\u001b[0m: (None, 1, 1, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m122 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /attention/max_pool/MaxPool\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/max_pool/MaxPool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_79/transpose:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [7, 7] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [7, 7] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_1/MaxPool2d:0 \u001b[34mshape\u001b[0m: (None, 1, 1, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n\n\u001b[32mINFO:\u001b[0m \u001b[32m123 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /attention/Reshape\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/avg_pool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: _v_287 \u001b[36mshape\u001b[0m: [2] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Reshape_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_82/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 2048] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m124 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /attention/Reshape_2\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/max_pool/MaxPool_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: _v_287 \u001b[36mshape\u001b[0m: [2] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Reshape_2_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_85/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 2048] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_1/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m125 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MatMul\u001b[35m onnx_op_name\u001b[0m: /attention/fc/fc.0/MatMul\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Reshape_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::MatMul_731 \u001b[36mshape\u001b[0m: [2048, 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/fc/fc.0/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.b\u001b[0m: \u001b[34mshape\u001b[0m: (2048, 128) \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_type\u001b[0m: \u001b[34mname\u001b[0m: float32 \u001b[34mshape\u001b[0m: () \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_1/MatMul:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m126 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MatMul\u001b[35m onnx_op_name\u001b[0m: /attention/fc/fc.0_1/MatMul\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Reshape_2_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::MatMul_731 \u001b[36mshape\u001b[0m: [2048, 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/fc/fc.0_1/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_1/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.b\u001b[0m: \u001b[34mshape\u001b[0m: (2048, 128) \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_type\u001b[0m: \u001b[34mname\u001b[0m: float32 \u001b[34mshape\u001b[0m: () \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_3/MatMul:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m127 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /attention/fc/fc.1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/fc/fc.0/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/fc/fc.1/Relu_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_1/MatMul:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m128 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /attention/fc/fc.1_1/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/fc/fc.0_1/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/fc/fc.1_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_3/MatMul:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m129 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MatMul\u001b[35m onnx_op_name\u001b[0m: /attention/fc/fc.2/MatMul\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/fc/fc.1/Relu_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::MatMul_732 \u001b[36mshape\u001b[0m: [128, 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/fc/fc.2/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_49/Relu:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.b\u001b[0m: \u001b[34mshape\u001b[0m: (128, 2048) \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_type\u001b[0m: \u001b[34mname\u001b[0m: float32 \u001b[34mshape\u001b[0m: () \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_5/MatMul:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m130 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MatMul\u001b[35m onnx_op_name\u001b[0m: /attention/fc/fc.2_1/MatMul\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/fc/fc.1_1/Relu_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 128] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::MatMul_732 \u001b[36mshape\u001b[0m: [128, 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/fc/fc.2_1/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_50/Relu:0 \u001b[34mshape\u001b[0m: (None, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.b\u001b[0m: \u001b[34mshape\u001b[0m: (128, 2048) \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.output_type\u001b[0m: \u001b[34mname\u001b[0m: float32 \u001b[34mshape\u001b[0m: () \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_7/MatMul:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m131 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /attention/Reshape_1\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/fc/fc.2/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__0', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: _v_289 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Reshape_1_output_0 \u001b[36mshape\u001b[0m: ['unk__2', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_5/MatMul:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 2048, 1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m132 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /attention/Reshape_3\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/fc/fc.2_1/MatMul_output_0 \u001b[36mshape\u001b[0m: ['unk__1', 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: _v_289 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Reshape_3_output_0 \u001b[36mshape\u001b[0m: ['unk__3', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.linalg.matmul_7/MatMul:0 \u001b[34mshape\u001b[0m: (None, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [-1, 2048, 1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_3/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m133 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Add\u001b[35m onnx_op_name\u001b[0m: /attention/Add\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Reshape_1_output_0 \u001b[36mshape\u001b[0m: ['unk__2', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /attention/Reshape_3_output_0 \u001b[36mshape\u001b[0m: ['unk__3', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Add_output_0 \u001b[36mshape\u001b[0m: ['unk__4', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: add\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_2/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_3/Reshape:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m134 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: /attention/sigmoid/Sigmoid\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Add_output_0 \u001b[36mshape\u001b[0m: ['unk__4', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/sigmoid/Sigmoid_output_0 \u001b[36mshape\u001b[0m: ['unk__4', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_101/Add:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid/Sigmoid:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m135 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /attention/Mul\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/features.7.2/relu_2/Relu_output_0 \u001b[36mshape\u001b[0m: ['batch_size', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /attention/sigmoid/Sigmoid_output_0 \u001b[36mshape\u001b[0m: ['unk__4', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Mul_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_96/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_97/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_23/Mul:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m136 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceMean\u001b[35m onnx_op_name\u001b[0m: /attention/ReduceMean\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Mul_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/ReduceMean_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.axis0\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_23/Mul:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_2/Mean:0 \u001b[34mshape\u001b[0m: (None, 1, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m137 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceMax\u001b[35m onnx_op_name\u001b[0m: /attention/ReduceMax\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Mul_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/ReduceMax_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_max\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.axis0\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_23/Mul:0 \u001b[34mshape\u001b[0m: (None, 2048, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_max_1/Max:0 \u001b[34mshape\u001b[0m: (None, 1, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m138 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /attention/Concat_4\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/ReduceMean_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /attention/ReduceMax_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Concat_4_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_2/Mean:0 \u001b[34mshape\u001b[0m: (None, 1, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_max_1/Max:0 \u001b[34mshape\u001b[0m: (None, 1, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat/concat:0 \u001b[34mshape\u001b[0m: (None, 2, 7, 7) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m139 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /attention/conv_spatial/Conv\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Concat_4_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.attention.conv_spatial.weight \u001b[36mshape\u001b[0m: [1, 2, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/conv_spatial/Conv_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_98/transpose:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (7, 7, 2, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_53/convolution:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m140 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Sigmoid\u001b[35m onnx_op_name\u001b[0m: /attention/sigmoid_1/Sigmoid\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/conv_spatial/Conv_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/sigmoid_1/Sigmoid_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: sigmoid\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.convolution_53/convolution:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_1/Sigmoid:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m141 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Mul\u001b[35m onnx_op_name\u001b[0m: /attention/Mul_1\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Mul_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /attention/sigmoid_1/Sigmoid_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 1, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /attention/Mul_1_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: multiply\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_99/transpose:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sigmoid_1/Sigmoid:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_26/Mul:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m142 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: GlobalAveragePool\u001b[35m onnx_op_name\u001b[0m: /pool/GlobalAveragePool\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Mul_1_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /pool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: reduce_mean\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_26/Mul:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1, 2] \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.keepdims\u001b[0m: \u001b[34mval\u001b[0m: True \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.reduce_mean_3/Mean:0 \u001b[34mshape\u001b[0m: (None, 1, 1, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m143 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Shape\u001b[35m onnx_op_name\u001b[0m: /Shape\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /attention/Mul_1_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 7, 7] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Shape_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: shape_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_26/Mul:0 \u001b[34mshape\u001b[0m: (None, 7, 7, 2048) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.out_type\u001b[0m: \u001b[34mname\u001b[0m: int64 \u001b[34mshape\u001b[0m: () \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.shape/wa/Shape:0 \u001b[34mshape\u001b[0m: (4,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m144 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gather\u001b[35m onnx_op_name\u001b[0m: /Gather\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Shape_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /attention/Constant_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Gather_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: strided_slice\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.params\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.shape/wa/Shape:0 \u001b[34mshape\u001b[0m: (4,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.indices\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add/AddV2:0 \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice/StridedSlice:0 \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m145 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Unsqueeze\u001b[35m onnx_op_name\u001b[0m: /Unsqueeze\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Gather_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Unsqueeze_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: identity\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.strided_slice/StridedSlice:0 \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.identity/Identity:0 \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m146 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Concat\u001b[35m onnx_op_name\u001b[0m: /Concat\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Unsqueeze_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Constant_1_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Concat_output_0 \u001b[36mshape\u001b[0m: [2] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: concat\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input0\u001b[0m: \u001b[34mname\u001b[0m: tf.identity/Identity:0 \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input1\u001b[0m: \u001b[34mshape\u001b[0m: (1,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.axis\u001b[0m: \u001b[34mval\u001b[0m: 0 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_1/concat:0 \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m147 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /Reshape\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /pool/GlobalAveragePool_output_0 \u001b[36mshape\u001b[0m: ['unk__5', 2048, 1, 1] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Concat_output_0 \u001b[36mshape\u001b[0m: [2] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Reshape_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_103/transpose:0 \u001b[34mshape\u001b[0m: (None, 2048, 1, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mname\u001b[0m: tf.concat_1/concat:0 \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_4/Reshape:0 \u001b[34mshape\u001b[0m: (None, None) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m148 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /fc/fc.0/Gemm\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Reshape_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.fc.0.weight \u001b[36mshape\u001b[0m: [1024, 2048] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: model.fc.0.bias \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /fc/fc.0/Gemm_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (None, None) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (2048, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (None, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m149 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: BatchNormalization\u001b[35m onnx_op_name\u001b[0m: /fc/fc.1/BatchNormalization\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc/fc.0/Gemm_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.fc.1.weight \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: model.fc.1.bias \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: model.fc.1.running_mean \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m: model.fc.1.running_var \u001b[36mshape\u001b[0m: [1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /fc/fc.1/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: BatchNormalization\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.X\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_1/AddV2:0 \u001b[34mshape\u001b[0m: (None, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.mean\u001b[0m: \u001b[34mname\u001b[0m: model.fc.1.running_mean \u001b[34mshape\u001b[0m: [1024] \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.variance\u001b[0m: \u001b[34mname\u001b[0m: model.fc.1.running_var \u001b[34mshape\u001b[0m: [1024] \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.offset\u001b[0m: \u001b[34mname\u001b[0m: model.fc.1.bias \u001b[34mshape\u001b[0m: [1024] \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.scale\u001b[0m: \u001b[34mshape\u001b[0m: (1024,) \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.6.variance_epsilon\u001b[0m: \u001b[34mval\u001b[0m: 9.999999747378752e-06 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_2/AddV2:0 \u001b[34mshape\u001b[0m: (None, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m150 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /fc/fc.2/Relu\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc/fc.1/BatchNormalization_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /fc/fc.2/Relu_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_2/AddV2:0 \u001b[34mshape\u001b[0m: (None, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_51/Relu:0 \u001b[34mshape\u001b[0m: (None, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m151 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Gemm\u001b[35m onnx_op_name\u001b[0m: /fc/fc.4/Gemm\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc/fc.2/Relu_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: model.fc.4.weight \u001b[36mshape\u001b[0m: [512, 1024] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: model.fc.4.bias \u001b[36mshape\u001b[0m: [512] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /fc/fc.4/Gemm_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: matmul\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: Placeholder:0 \u001b[34mshape\u001b[0m: (None, 1024) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mshape\u001b[0m: (1024, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.z\u001b[0m: \u001b[34mshape\u001b[0m: (512,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.4.alpha\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.5.beta\u001b[0m: \u001b[34mval\u001b[0m: 1.0 \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_3/AddV2:0 \u001b[34mshape\u001b[0m: (None, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m152 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: ReduceL2\u001b[35m onnx_op_name\u001b[0m: /ReduceL2\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc/fc.4/Gemm_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /ReduceL2_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: l2_normalize\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_3/AddV2:0 \u001b[34mshape\u001b[0m: (None, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sqrt/Sqrt:0 \u001b[34mshape\u001b[0m: (None, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m153 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Shape\u001b[35m onnx_op_name\u001b[0m: /Shape_1\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc/fc.4/Gemm_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Shape_1_output_0 \u001b[36mshape\u001b[0m: ['unk__6'] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: shape_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_3/AddV2:0 \u001b[34mshape\u001b[0m: (None, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.out_type\u001b[0m: \u001b[34mname\u001b[0m: int64 \u001b[34mshape\u001b[0m: () \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.shape_2/wa/Shape_1:0 \u001b[34mshape\u001b[0m: (2,) \u001b[34mdtype\u001b[0m: <dtype: 'int64'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m154 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Clip\u001b[35m onnx_op_name\u001b[0m: /Clip\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /ReduceL2_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Constant_2_output_0 \u001b[36mshape\u001b[0m: [] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Clip_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: maximum\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.sqrt/Sqrt:0 \u001b[34mshape\u001b[0m: (None, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.min_value\u001b[0m: \u001b[34mshape\u001b[0m: () \u001b[34mdtype\u001b[0m: float32 \n\u001b[32mINFO:\u001b[0m \u001b[34m input.3.max_value\u001b[0m: \u001b[34mname\u001b[0m:  \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum/Maximum:0 \u001b[34mshape\u001b[0m: (None, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m155 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Expand\u001b[35m onnx_op_name\u001b[0m: /Expand\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Clip_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Shape_1_output_0 \u001b[36mshape\u001b[0m: ['unk__6'] \u001b[36mdtype\u001b[0m: int64\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Expand_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: expand_dims_v2\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input_tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.math.maximum/Maximum:0 \u001b[34mshape\u001b[0m: (None, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.input_tensor_shape\u001b[0m: \u001b[34mval\u001b[0m: [<KerasTensor: shape=() dtype=int64 (created by layer 'tf.__operators__.getitem_10')>, <KerasTensor: shape=() dtype=int64 (created by layer 'tf.__operators__.getitem_11')>] \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_35/Mul:0 \u001b[34mshape\u001b[0m: (None, None) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[32mINFO:\u001b[0m \u001b[32m156 / 156\u001b[0m\n\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Div\u001b[35m onnx_op_name\u001b[0m: /Div\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /fc/fc.4/Gemm_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Expand_output_0 \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: biometric_embedding \u001b[36mshape\u001b[0m: ['batch_size', 'Divbiometric_embedding_dim_1'] \u001b[36mdtype\u001b[0m: float32\n\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: divide\n\u001b[32mINFO:\u001b[0m \u001b[34m input.1.x\u001b[0m: \u001b[34mname\u001b[0m: tf.__operators__.add_3/AddV2:0 \u001b[34mshape\u001b[0m: (None, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m input.2.y\u001b[0m: \u001b[34mname\u001b[0m: tf.math.multiply_35/Mul:0 \u001b[34mshape\u001b[0m: (None, None) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.divide/truediv:0 \u001b[34mshape\u001b[0m: (None, 512) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n\n\u001b[07msaved_model output started\u001b[0m ==========================================================\nSaved artifact at 'tf_saved_model'. The following endpoints are available:\n\n* Endpoint 'serving_default'\n  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_image')\nOutput Type:\n  TensorSpec(shape=(None, 512), dtype=tf.float32, name=None)\n\u001b[32msaved_model output complete!\u001b[0m\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1772063986.341521     187 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1772063986.341594     187 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1772063986.609394     187 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n\u001b[32mFloat32 tflite output complete!\u001b[0m\nW0000 00:00:1772064120.214507     187 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1772064120.214540     187 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n\u001b[32mFloat16 tflite output complete!\u001b[0m\nCheck the 'livestock_tflite_out' folder for your .tflite file!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"tf_saved_model\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Optional: smaller model\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"livestock_biometric.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"✅ TFLite model saved successfully!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-26T00:11:31.385167Z",
          "iopub.execute_input": "2026-02-26T00:11:31.38593Z",
          "iopub.status.idle": "2026-02-26T00:11:37.309033Z",
          "shell.execute_reply.started": "2026-02-26T00:11:31.385901Z",
          "shell.execute_reply": "2026-02-26T00:11:37.308219Z"
        },
        "id": "NKGx1VgpUvsB",
        "outputId": "070922f1-3c48-426b-d2a3-7ff486fb0833"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "I0000 00:00:1772064692.004471      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9085 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1772064692.009579      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1772064694.451138      55 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1772064694.451180      55 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1772064694.623788      55 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "✅ TFLite model saved successfully!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def visualize_preprocessing_audit(dataloader, n_samples=3):\n",
        "    \"\"\"\n",
        "    Visualizes how the model 'sees' the data after augmentation and normalization.\n",
        "    Essential for catching 'over-cropping' or 'over-blurring' in production.\n",
        "    \"\"\"\n",
        "    anchors, positives, negatives = next(iter(dataloader))\n",
        "\n",
        "    fig, axes = plt.subplots(n_samples, 3, figsize=(12, n_samples * 4))\n",
        "    plt.suptitle(\"Preprocessing Audit: Anchor | Positive | Negative\", fontsize=16)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        for j, img_tensor in enumerate([anchors[i], positives[i], negatives[i]]):\n",
        "            # Denormalize for visualization\n",
        "            img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "            img = (img * [0.229, 0.224, 0.225]) + [0.485, 0.456, 0.406]\n",
        "            img = np.clip(img, 0, 1)\n",
        "\n",
        "            axes[i, j].imshow(img)\n",
        "            axes[i, j].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run this before training starts\n",
        "visualize_preprocessing_audit(train_loader)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-25T23:45:46.368055Z",
          "iopub.status.idle": "2026-02-25T23:45:46.368352Z",
          "shell.execute_reply.started": "2026-02-25T23:45:46.368222Z",
          "shell.execute_reply": "2026-02-25T23:45:46.368241Z"
        },
        "id": "xn3NtAZYUvsC"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}